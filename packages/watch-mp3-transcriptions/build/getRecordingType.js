"use strict";var __awaiter=this&&this.__awaiter||function(e,n,t,o){return new(t||(t=Promise))((function(r,i){function s(e){try{u(o.next(e))}catch(e){i(e)}}function a(e){try{u(o.throw(e))}catch(e){i(e)}}function u(e){var n;e.done?r(e.value):(n=e.value,n instanceof t?n:new t((function(e){e(n)}))).then(s,a)}u((o=o.apply(e,n||[])).next())}))},__generator=this&&this.__generator||function(e,n){var t,o,r,i,s={label:0,sent:function(){if(1&r[0])throw r[1];return r[1]},trys:[],ops:[]};return i={next:a(0),throw:a(1),return:a(2)},"function"==typeof Symbol&&(i[Symbol.iterator]=function(){return this}),i;function a(a){return function(u){return function(a){if(t)throw new TypeError("Generator is already executing.");for(;i&&(i=0,a[0]&&(s=0)),s;)try{if(t=1,o&&(r=2&a[0]?o.return:a[0]?o.throw||((r=o.return)&&r.call(o),0):o.next)&&!(r=r.call(o,a[1])).done)return r;switch(o=0,r&&(a=[2&a[0],r.value]),a[0]){case 0:case 1:r=a;break;case 4:return s.label++,{value:a[1],done:!1};case 5:s.label++,o=a[1],a=[0];continue;case 7:a=s.ops.pop(),s.trys.pop();continue;default:if(!(r=s.trys,(r=r.length>0&&r[r.length-1])||6!==a[0]&&2!==a[0])){s=0;continue}if(3===a[0]&&(!r||a[1]>r[0]&&a[1]<r[3])){s.label=a[1];break}if(6===a[0]&&s.label<r[1]){s.label=r[1],r=a;break}if(r&&s.label<r[2]){s.label=r[2],s.ops.push(a);break}r[2]&&s.ops.pop(),s.trys.pop();continue}a=n.call(e,s)}catch(e){a=[6,e],o=0}finally{t=r=0}if(5&a[0])throw a[1];return{value:a[0]?a[1]:void 0,done:!0}}([a,u])}}};Object.defineProperty(exports,"__esModule",{value:!0}),exports.getRecordingType=exports.CHUNK_TOKEN_SIZE=void 0;var ai_models_1=require("ai-models"),transcriptionToGptChunks_1=require("./transcriptionToGptChunks");exports.CHUNK_TOKEN_SIZE=2048;
/**
 Function that uses AI (LLM's mostly) that tries to determine the recording type from a transcription from an audio.

 Uses `Transcription` file, then chunks the english text, and tries to determine the type as efficiently as possible.
 */
var getRecordingType=function(e){return __awaiter(void 0,void 0,void 0,(function(){var n,t,o,r,i;return __generator(this,(function(s){switch(s.label){case 0:return[4/*yield*/,(0,transcriptionToGptChunks_1.transcriptionToGptChunks)(e,exports.CHUNK_TOKEN_SIZE)];case 1:return(n=s.sent())?n.length>4?[4/*yield*/,(0,ai_models_1.textToText)("Does this text seem to be a transcription of an audiobook?\n\n---\n".concat(n[0],'\n---\n\nRespond with "true" if it does, "false" otherwise.\n'))]:[3/*break*/,3]:[2/*return*/,"unknown"];case 2:if(t=s.sent(),"true"===(null===(r=t.result)||void 0===r?void 0:r.trim()))return[2/*return*/,"audiobook"];s.label=3;case 3:return[4/*yield*/,(0,ai_models_1.textToText)("Does this text seem to be a transcription of music?\n\n---\n".concat(n[0],'\n---\n\nRespond with "true" if it does, "false" otherwise.\n'))];case 4:return o=s.sent(),"true"===(null===(i=o.result)||void 0===i?void 0:i.trim())?[2/*return*/,"music"]:[4/*yield*/,n.reduce((function(e,n){return __awaiter(void 0,void 0,void 0,(function(){var t,o,r;return __generator(this,(function(i){switch(i.label){case 0:return[4/*yield*/,e];case 1:
// already determined, don't do more stuff
return"unknown"!==(t=i.sent())?[2/*return*/,t]:(o='Consider this transcript, and classify it into one of the following: "conversation", "monologue", "voicemail", "code", "unknown", "other". \n\n\n ---\n'.concat(n,'\n---\nIf you don\'t know for sure, reply with "unknown". Reply with only the word of the classification.'),[4/*yield*/,(0,ai_models_1.textToText)(o)]);case 2:return(r=i.sent().result)?r.includes("conversation")?[2/*return*/,"conversation"]:r.includes("monologue")?[2/*return*/,"monologue"]:r.includes("code")?[2/*return*/,"code"]:r.includes("voicemail")?[2/*return*/,"voicemail"]:r.includes("other")?[2/*return*/,"other"]:[2/*return*/,"unknown"]:[2/*return*/,t]}}))}))}),new Promise((function(e){return e("unknown")})))];case 5:return[2/*return*/,s.sent()]}}))}))};exports.getRecordingType=getRecordingType;
//# sourceMappingURL=getRecordingType.js.map