{
  "createdAt": 1678369226448,
  "updatedAt": 1678369226448,
  "deletedAt": 0,
  "createdFirstAt": 1678369226448,
  "isApiExposed": false,
  "isExported": true,
  "operationRelativeTypescriptFilePath": "src/textToText.ts",
  "commentsInside": [],
  "rawText": " async (\n  text: string,\n  config?: {\n    personId?: string;\n    /**\n     * Model defaults to gpt default.\n     */\n    model?: TextToTextModelEnum;\n    /**\n     * By default, the query to the api is delayed to avoid the ratelimit from happening. If you want to avoid the delay, set this to true\n     */\n    isInstant?: boolean;\n  }\n): Promise<\n  StandardResponse & {\n    result?: string | undefined;\n  }\n> => {\n  if (!config?.model || openAiTextCompletionModels.includes(config?.model)) {\n    const gpt3result = await gpt3(text, {\n      model: config?.model as OpenAiTextCompletionModelEnum | undefined,\n    });\n\n    const pagesCount = Math.ceil(calculateTokenCount(text) / 500);\n    const priceCredit = pagesCount * 0.1;\n    return {\n      ...gpt3result,\n      payment: {\n        personId: config?.personId,\n        priceCredit,\n        priceDescription: `Estimated ${pagesCount} pages`,\n      },\n    };\n  }\n  const message = `${config?.model} not implemented yet`;\n  console.log(message);\n  return { isSuccessful: false, message };\n}",
  "name": "textToText",
  "slug": "text-to-text",
  "parameters": [
    {
      "name": "text",
      "schema": {
        "type": "string"
      },
      "simplifiedSchema": {
        "type": "string"
      },
      "required": true
    },
    {
      "name": "config",
      "schema": {
        "type": "object",
        "properties": {
          "personId": {
            "type": "string"
          },
          "model": {
            "$ref": "#/definitions/TextToTextModelEnum",
            "description": "Model defaults to gpt default."
          },
          "isInstant": {
            "type": "boolean",
            "description": "By default, the query to the api is delayed to avoid the ratelimit from happening. If you want to avoid the delay, set this to true"
          }
        },
        "additionalProperties": false
      },
      "simplifiedSchema": {
        "properties": [
          {
            "name": "personId",
            "required": false,
            "schema": {
              "type": "string"
            }
          },
          {
            "name": "model",
            "required": false,
            "schema": {
              "fullComment": "Model defaults to gpt default.\n\n",
              "properties": [],
              "type": "object"
            }
          },
          {
            "name": "isInstant",
            "required": false,
            "schema": {
              "fullComment": "By default, the query to the api is delayed to avoid the ratelimit from happening. If you want to avoid the delay, set this to true",
              "type": "boolean"
            }
          }
        ],
        "type": "object"
      },
      "required": false
    }
  ],
  "description": "TODO: improve gpt3 api with good token calculation, aggresive exponential backoff, and preventing ratelimit at all times, to maximise stability. can I have gpt3 as fallback to browser automated ChatGPT?\n\n\nFor now it's `string -> string`\n\nThere are simply too many options to make this file -> file, it wouldn't be useful.\n\nNB: use oneByOne for this if you don't want to hit the limit\n\n`textToText` needs to have a warning for context size (or dynamically choose a LLM with a bigger context size, or warn and split it up based on sentence endings, paragraphs, and newlines. It always needs to work!)\n\nFix errors:\n\n- ratelimit reached\n- too many tokens used (more than 4k)",
  "returnType": {
    "rawType": "Promise<import(\"/Users/clarity/os/operations/tools/purpose/codebase-introspection/functions/function-types/build/StandardResponse\").StandardResponse & { result?: string | undefined; }>",
    "typeCoverage": 0,
    "isArray": false,
    "isEnum": false,
    "isObject": false,
    "isPrimitive": false,
    "isEnumLiteral": false
  },
  "maxIndentationDepth": 4,
  "size": {
    "characters": 1705,
    "lines": 52,
    "bytes": 1705,
    "bytesPerCharacter": 1,
    "charactersPerLine": 33,
    "linesPerFile": 52,
    "numberOfFiles": 1
  },
  "id": "elykksagqljaumumgqoxzirk"
}